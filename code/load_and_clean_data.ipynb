{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This notebook is used to process the raw transcripts into a format that can then be used for model training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env/python\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import string\n",
    "import unicodedata\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Subset 1 and Subset 2\n",
    "path1 = '../data/Subset 1/'\n",
    "subdirs = glob.glob('%s*'%(path1))\n",
    "\n",
    "path2 = '../data/Subset 2/'\n",
    "subdirs.extend(glob.glob('%s*'%(path2)))                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_label(label):\n",
    "    if label == '1':\n",
    "        return '0'\n",
    "    elif label =='2':\n",
    "        return '1'\n",
    "    elif label =='3':\n",
    "        return '2'\n",
    "    elif label =='4':\n",
    "        return '3'\n",
    "    elif label =='5':\n",
    "        return '4'\n",
    "    elif label =='8':\n",
    "        return '5'\n",
    "    elif label =='9':\n",
    "        return '6'\n",
    "    else:\n",
    "        return 'nan'\n",
    "    \n",
    "def resolve_slabel(label):\n",
    "    if label == '1':\n",
    "        return '0'\n",
    "    elif label =='2':\n",
    "        return '1'\n",
    "    elif label =='3':\n",
    "        return '2'\n",
    "    elif label =='4':\n",
    "        return '3'\n",
    "    elif label =='5':\n",
    "        return '4'\n",
    "    else:\n",
    "        return 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504 63\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "To avoid overfitting the models we carefully divide the training and testing set. \n",
    "Testing set include some teachers who particiapted in Year 1. The transcripts from these teachers are not included\n",
    "in the training set. The teachers in this list were picked at random.\n",
    "'''\n",
    "\n",
    "train_subdirs =[]\n",
    "test_subdirs = []\n",
    "for item in subdirs:\n",
    "    if item.find(\"Travers.Spring\") != -1 or item.find(\"Benson\") != -1 \\\n",
    "    or item.find(\"Carroll\") != -1 or item.find(\"Saunders.Spring\") != -1 \\\n",
    "    or item.find(\"Keene\") != -1 or item.find(\"Carter\") != -1 or item.find(\"Basker\") != -1 :\n",
    "        test_subdirs.append(item)\n",
    "    else:\n",
    "        train_subdirs.append(item)\n",
    "print(len(train_subdirs), len(test_subdirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19919/3975454404.py:12: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  mask = load_data['Sentence'].str.contains('(.*[\\(].*|.*[\\)].*|.*[\\[].*|.*[\\]].*)|(^[.?!]+$)|(^.*[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}.*$)',regex=True,na=False)\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "temp = []\n",
    "flag = 0\n",
    "for dir in train_subdirs: #replace with test_subdirs to generate test data\n",
    "    if dir.endswith('.xlsx') and not dir.startswith('~'):\n",
    "        try:\n",
    "            temp_data = None\n",
    "            load_data = pd.read_excel(dir, engine='openpyxl')\n",
    "            #print(dir, load_data.columns)\n",
    "            load_data['Sentence'] = load_data['Sentence'].str.replace(\"[\\(\\[].*?[\\)\\]]\", \"\", regex=True)\n",
    "            load_data = load_data[load_data['Sentence'] != \"\"]\n",
    "            mask = load_data['Sentence'].str.contains('(.*[\\(].*|.*[\\)].*|.*[\\[].*|.*[\\]].*)|(^[.?!]+$)|(^.*[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}.*$)',regex=True,na=False)\n",
    "            temp_data = load_data[:][~mask]\n",
    "            temp_data = temp_data.loc[:, ~temp_data.columns.str.contains('^Unnamed')]\n",
    "            temp_data['Transcript'] = dir.split('/')[len(dir.split('/'))-1]\n",
    "            for item in temp_data.columns:\n",
    "                if item not in ['Teacher Tag', 'TimeStamp' ,'Turn','Student Tag','Sentence','Speaker','Transcript']:\n",
    "                    temp_data = temp_data.drop(columns=[item])\n",
    "            if flag == 0:\n",
    "                data = temp_data\n",
    "                flag = 1\n",
    "            else:\n",
    "                if len(data.columns) > 8:\n",
    "                    print(data.columns,dir)\n",
    "                data = data.append(temp_data, ignore_index=True,sort=False)\n",
    "        except Exception as e:\n",
    "            print(e,dir)\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205313, 567)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "bad_sentences = []\n",
    "bad_speakers = []\n",
    "num_sentences = []\n",
    "bad_entries = []\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "for entry in data.iterrows():\n",
    "    try:\n",
    "        if type(entry[1]['Speaker']) == int or entry[1]['Speaker'] == float:\n",
    "            bad_speakers.append(entry[1]['Speaker'])\n",
    "            continue\n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'datetime.time'>\" or repr(type(entry[1]['Sentence'])) == \"<type 'datetime.datetime'>\" or repr(entry[1]['Speaker']) == 'nan':\n",
    "            bad_sentences.append(entry[1]['Sentence'])\n",
    "            continue\n",
    "    \n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'int'>\" or repr(type(entry[1]['Sentence'])) == \"<type 'float'>\":\n",
    "            num_sentences.append(str(entry[1]['Sentence']))\n",
    "            entry[1]['Sentence'] = str(entry[1]['Sentence']).translate(translator)\n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'str'>\":\n",
    "            entry[1]['Sentence'] = str(entry[1]['Sentence']).translate(translator)\n",
    "            \n",
    "        temp = unicodedata.normalize('NFKD', str(entry[1]['Sentence']).translate(translator))\n",
    "        \n",
    "        # Turn, Speaker, Sentence, Tag\n",
    "        try:\n",
    "            tag = resolve_label(str(entry[1]['Teacher Tag']).split('-')[0].strip())\n",
    "        except Exception as e:\n",
    "            print(e,'####')\n",
    "        try:\n",
    "            stag = resolve_slabel(str(entry[1]['Student Tag']).split('-')[0].strip())\n",
    "        except Exception as e:\n",
    "            print(e,'####')\n",
    "        \n",
    "        sent = ' '.join([re.sub(r\"[^a-zA-Z0-9]+\", ' ', k) for k in temp.split(\" \")])\n",
    "        \n",
    "        if str(stag) != 'nan':\n",
    "            #print([entry[1]['Turn'],'S',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "            dataset.append([entry[1]['Turn'],'S',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "        elif str(tag) != 'nan':\n",
    "            #print([entry[1]['Turn'],'T',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "            dataset.append([entry[1]['Turn'],'T',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        bad_entries.append([entry[1]['Sentence'], entry[1]['Speaker']])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Turn</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "      <th>StudentTag</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>My names Ms Villarin I dont know if Ms Ferrant...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>7th grade math.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>So today her and I will be teaching a lesson t...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>7th grade math.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>So you can treat me the way you treat her if y...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>7th grade math.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Okay</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>7th grade math.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>So today were going to be doing a really cool ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>7th grade math.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203645</th>\n",
       "      <td>7</td>\n",
       "      <td>T</td>\n",
       "      <td>I sent it to you</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year2.Wolfram.Fall.121720-3.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203646</th>\n",
       "      <td>8</td>\n",
       "      <td>S</td>\n",
       "      <td>All right thank you</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>TalkBack.Year2.Wolfram.Fall.121720-3.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203647</th>\n",
       "      <td>9</td>\n",
       "      <td>T</td>\n",
       "      <td>But you should get in there and you actually d...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year2.Wolfram.Fall.121720-3.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203648</th>\n",
       "      <td>9</td>\n",
       "      <td>T</td>\n",
       "      <td>There you go</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year2.Wolfram.Fall.121720-3.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203649</th>\n",
       "      <td>10</td>\n",
       "      <td>S</td>\n",
       "      <td>All right</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>TalkBack.Year2.Wolfram.Fall.121720-3.xlsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203601 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Turn Speaker                                           Sentence  Tag  \\\n",
       "0       1.0       T  My names Ms Villarin I dont know if Ms Ferrant...    0   \n",
       "1       1.0       T  So today her and I will be teaching a lesson t...    0   \n",
       "2       1.0       T  So you can treat me the way you treat her if y...    0   \n",
       "3       1.0       T                                               Okay    0   \n",
       "4       1.0       T  So today were going to be doing a really cool ...    0   \n",
       "...     ...     ...                                                ...  ...   \n",
       "203645    7       T                                   I sent it to you    0   \n",
       "203646    8       S                                All right thank you  nan   \n",
       "203647    9       T  But you should get in there and you actually d...    0   \n",
       "203648    9       T                                       There you go    0   \n",
       "203649   10       S                                          All right  nan   \n",
       "\n",
       "       StudentTag                                 Transcript  \n",
       "0             nan                        7th grade math.xlsx  \n",
       "1             nan                        7th grade math.xlsx  \n",
       "2             nan                        7th grade math.xlsx  \n",
       "3             nan                        7th grade math.xlsx  \n",
       "4             nan                        7th grade math.xlsx  \n",
       "...           ...                                        ...  \n",
       "203645        nan  TalkBack.Year2.Wolfram.Fall.121720-3.xlsx  \n",
       "203646          0  TalkBack.Year2.Wolfram.Fall.121720-3.xlsx  \n",
       "203647        nan  TalkBack.Year2.Wolfram.Fall.121720-3.xlsx  \n",
       "203648        nan  TalkBack.Year2.Wolfram.Fall.121720-3.xlsx  \n",
       "203649          0  TalkBack.Year2.Wolfram.Fall.121720-3.xlsx  \n",
       "\n",
       "[203601 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Turn':[i[0] for i in dataset], 'Speaker':[i[1] for i in dataset], 'Sentence':[i[2] for i in dataset], 'Tag':[i[3] for i in dataset],'StudentTag':[i[4] for i in dataset],'Transcript':[i[5] for i in dataset]})\n",
    "df = df.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df = df[df['Sentence'] != '']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Sentence'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Speaker']=='S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  Number transcripts - 567\n",
    "  Number of teacher utterances - 165,674\n",
    "  Number of words (with repetitions) - 1,700,036\n",
    "  Number of unique words - 15,749\n",
    "  Number of student utterances - 56,580\n",
    "  Number of Turns - 87,071\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sorted(df['Transcript'].unique()):\n",
    "    print(item, len(df[df['Transcript']==item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['Speaker'] == 'T']\n",
    "temp_df['Tag'].value_counts(), temp_df['Tag'].value_counts().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['Sentence'].apply(lambda x: len(str(x).split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfTurns, prevTurn = 0, ''\n",
    "for item in df.iterrows():\n",
    "    if prevTurn == '': \n",
    "        numberOfTurns += 1\n",
    "        prevTurn = str(item[1]['Turn'])\n",
    "    if str(item[1]['Turn']) != str(prevTurn):\n",
    "        numberOfTurns += 1\n",
    "        prevTurn = str(item[1]['Turn'])\n",
    "print(numberOfTurns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df['Sentence'].str.lower().str.findall(\"\\w+\")\n",
    "\n",
    "unique = set()\n",
    "\n",
    "for x in words:\n",
    "    unique.update(x)\n",
    "print(len(words),len(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[df['Speaker']=='T']\n",
    "df2.groupby('Tag').agg(['count', 'size', 'nunique']).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../data/train_data_504.xlsx') #replace with test_data_63 for test data\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-processing \n",
    "\n",
    "- All lower cased\n",
    "- All punctuation removed\n",
    "- Converted all teachers to T tags\n",
    "- Converted all students to S tags\n",
    "- T labels range from  [0-6] - 0 stands for None\n",
    "- S are labelled None\n",
    "- Compiled all the data into single excel sheet\n",
    "- At present there are 91891 sentences in total\n",
    "\n",
    "Cleaning\n",
    "\n",
    "- [End of Class], [Class Ends] - Sentence in brackets\n",
    "- If Sentence contains a timestamp or date time stamp\n",
    "- If sentence is just . or ! or ? or empty\n",
    "- Speaker is a number (All of them are nans)\n",
    "- Speaker is nan\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52683 {0.0, 1.0, 2.0, 3.0, 4.0}\n"
     ]
    }
   ],
   "source": [
    "#Prepare Tuples from data - Student\n",
    "data = pd.read_excel('../data/train_data_504.xlsx') #replace with test_data_63 to generate test data\n",
    "empty_previous = ''\n",
    "sentence_tuple = []\n",
    "y = []\n",
    "flag  = 0\n",
    "# T->T 0->1 T->S S->S S->T\n",
    "for row in data.iterrows():\n",
    "    if row[1]['Speaker'] == 'T' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag=1\n",
    "        sentence_tuple.append([empty_previous,temp,row[1]['StudentTag']])\n",
    "        y.append(row[1]['StudentTag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 1:\n",
    "        sentence_tuple.append([temp,row[1]['Sentence'],row[1]['StudentTag']])\n",
    "        y.append(row[1]['StudentTag'])\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "        \n",
    "df = pd.DataFrame({'text_a':[i[0] for i in sentence_tuple], 'text_b':[i[1] for i in sentence_tuple], 'labels':[i[2] for i in sentence_tuple]})\n",
    "print(len(df),set(y))\n",
    "df.to_csv('../data/train_student.tsv',sep='\\t',index=False)   #replace with test_student to generate test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150918 {0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0}\n"
     ]
    }
   ],
   "source": [
    "#Prepare Tuples from data - teacher\n",
    "data = pd.read_excel('../data/train_data_504.xlsx') #replace with test_data_63 to generate test data\n",
    "empty_student = ''\n",
    "sentence_tuple = []\n",
    "y = []\n",
    "flag  = 0\n",
    "# T->T 0->1 T->S S->S S->T\n",
    "for row in data.iterrows():\n",
    "    if row[1]['Speaker'] == 'S' and flag == 2:\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 2\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        sentence_tuple.append([empty_student,temp,row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        sentence_tuple.append([empty_student,temp,row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 2:\n",
    "        sentence_tuple.append([temp,row[1]['Sentence'],row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        flag = 1\n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame({'text_a':[i[0] for i in sentence_tuple], 'text_b':[i[1] for i in sentence_tuple], 'labels':[i[2] for i in sentence_tuple]})\n",
    "print(len(df),set(y))\n",
    "df.to_csv('../data/train_teacher.tsv',sep='\\t',index=False)  #replace with test_teacher to generate test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p38] *",
   "language": "python",
   "name": "conda-env-pytorch_p38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
