{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This notebook is used to process the raw transcripts into a format that can then be used for model training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env/python\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import string\n",
    "import unicodedata\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Subset 1 and Subset 2\n",
    "path1 = '../data/Subset 1/'\n",
    "subdirs = glob.glob('%s*'%(path1))\n",
    "\n",
    "path2 = '../data/Subset 2/'\n",
    "subdirs.extend(glob.glob('%s*'%(path2)))                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_label(label):\n",
    "    if label == '1':\n",
    "        return '0'\n",
    "    elif label =='2':\n",
    "        return '1'\n",
    "    elif label =='3':\n",
    "        return '2'\n",
    "    elif label =='4':\n",
    "        return '3'\n",
    "    elif label =='5':\n",
    "        return '4'\n",
    "    elif label =='8':\n",
    "        return '5'\n",
    "    elif label =='9':\n",
    "        return '6'\n",
    "    elif label =='7':\n",
    "        return None\n",
    "    \n",
    "def resolve_slabel(label):\n",
    "    if label == '1':\n",
    "        return '0'\n",
    "    elif label =='2':\n",
    "        return '1'\n",
    "    elif label =='3':\n",
    "        return '2'\n",
    "    elif label =='4':\n",
    "        return '3'\n",
    "    elif label =='5':\n",
    "        return '4'\n",
    "    else:\n",
    "        return 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 63\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "To avoid overfitting the models we carefully divide the training and testing set. \n",
    "Testing set include some teachers who particiapted in Year 1. The transcripts from these teachers are not included\n",
    "in the training set. The teachers in this list were picked at random.\n",
    "'''\n",
    "\n",
    "train_subdirs =[]\n",
    "test_subdirs = []\n",
    "for item in subdirs:\n",
    "    if item.find(\"Travers.Spring\") != -1 or item.find(\"Barry.Spring\") != -1 \\\n",
    "    or item.find(\"Carroll\") != -1 or item.find(\"Saunders.Spring\") != -1 \\\n",
    "    or item.find(\"Keene\") != -1 or item.find(\"Carter\") != -1 or item.find(\"Basker\") != -1 :\n",
    "        test_subdirs.append(item)\n",
    "    else:\n",
    "        train_subdirs.append(item)\n",
    "print(len(train_subdirs), len(test_subdirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/strings/accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "temp = []\n",
    "flag = 0\n",
    "for dir in train_subdirs: #replace with test_subdirs to generate test data\n",
    "    if dir.endswith('.xlsx') and not dir.startswith('~'):\n",
    "        try:\n",
    "            temp_data = None\n",
    "            load_data = pd.read_excel(dir)\n",
    "            load_data['Sentence'] = load_data['Sentence'].str.replace(\"[\\(\\[].*?[\\)\\]]\", \"\", regex=True)\n",
    "            load_data = load_data[load_data['Sentence'] != \"\"]\n",
    "            mask = load_data['Sentence'].str.contains('(.*[\\(].*|.*[\\)].*|.*[\\[].*|.*[\\]].*)|(^[.?!]+$)|(^.*[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}.*$)',regex=True,na=False)\n",
    "            temp_data = load_data[:][~mask]\n",
    "            temp_data = temp_data.loc[:, ~temp_data.columns.str.contains('^Unnamed')]\n",
    "            temp_data['Transcript'] = dir.split('/')[len(dir.split('/'))-1]\n",
    "            for item in temp_data.columns:\n",
    "                if item not in ['Teacher Tag', 'TimeStamp' ,'Turn','Student Tag','Sentence','Speaker','Transcript']:\n",
    "                    temp_data = temp_data.drop(columns=[item])\n",
    "            if flag == 0:\n",
    "                data = temp_data\n",
    "                flag = 1\n",
    "            else:\n",
    "                if len(data.columns) > 8:\n",
    "                    print(data.columns,dir)\n",
    "                data = data.append(temp_data, ignore_index=True,sort=False)\n",
    "        except Exception as e:\n",
    "            print(e,dir)\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "bad_sentences = []\n",
    "bad_speakers = []\n",
    "num_sentences = []\n",
    "bad_entries = []\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "for entry in data.iterrows():\n",
    "    try:\n",
    "        if type(entry[1]['Speaker']) == int or entry[1]['Speaker'] == float:\n",
    "            bad_speakers.append(entry[1]['Speaker'])\n",
    "            continue\n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'datetime.time'>\" or repr(type(entry[1]['Sentence'])) == \"<type 'datetime.datetime'>\" or repr(entry[1]['Speaker']) == 'nan':\n",
    "            bad_sentences.append(entry[1]['Sentence'])\n",
    "            continue\n",
    "    \n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'int'>\" or repr(type(entry[1]['Sentence'])) == \"<type 'float'>\":\n",
    "            num_sentences.append(str(entry[1]['Sentence']))\n",
    "            entry[1]['Sentence'] = str(entry[1]['Sentence']).translate(translator)\n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'str'>\":\n",
    "            entry[1]['Sentence'] = str(entry[1]['Sentence']).translate(translator)\n",
    "            \n",
    "        temp = unicodedata.normalize('NFKD', str(entry[1]['Sentence']).translate(translator))\n",
    "        \n",
    "        # Turn, Speaker, Sentence, Tag\n",
    "        try:\n",
    "            tag = str(entry[1]['Teacher Tag']).split('-')[0].strip()\n",
    "        except Exception as e:\n",
    "            print(e,'####')\n",
    "        try:\n",
    "            stag = str(entry[1]['Student Tag']).split('-')[0].strip()\n",
    "        except Exception as e:\n",
    "            print(e,'####')\n",
    "        \n",
    "        sent = ' '.join([re.sub(r\"[^a-zA-Z0-9]+\", ' ', k) for k in temp.split(\" \")])\n",
    "        \n",
    "        if str(stag) != 'nan':\n",
    "            #print([entry[1]['Turn'],'S',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "            dataset.append([entry[1]['Turn'],'S',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "        elif str(tag) != 'nan':\n",
    "            #print([entry[1]['Turn'],'T',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "            dataset.append([entry[1]['Turn'],'T',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        bad_entries.append([entry[1]['Sentence'], entry[1]['Speaker']])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Turn</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "      <th>StudentTag</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Arina youre right here next to Eric</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.021820.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Haha</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.021820.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>All right ladies and gentlemen open up to your...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.021820.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>We already started working on that</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.021820.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>The focus right now with your partner is to wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.021820.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>112.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Now what Id like to do we only have about five...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.020620-1.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>112.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Then Ill probably give you time tomorrow</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.020620-1.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26298</th>\n",
       "      <td>113.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Go ahead and turn them in and then you can lea...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.020620-1.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>114.0</td>\n",
       "      <td>T</td>\n",
       "      <td>If theres a specific type of problem you want ...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.020620-1.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>114.0</td>\n",
       "      <td>T</td>\n",
       "      <td>If you would go ahead and turn off the microph...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>TalkBack.Year1.Saunders.Spring.020620-1.xlsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26301 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Turn Speaker                                           Sentence  Tag  \\\n",
       "0        1.0       T                Arina youre right here next to Eric    1   \n",
       "1        2.0       S                                               Haha  nan   \n",
       "2        3.0       T  All right ladies and gentlemen open up to your...    1   \n",
       "3        3.0       T                 We already started working on that    1   \n",
       "4        3.0       T  The focus right now with your partner is to wo...    1   \n",
       "...      ...     ...                                                ...  ...   \n",
       "26296  112.0       T  Now what Id like to do we only have about five...    1   \n",
       "26297  112.0       T           Then Ill probably give you time tomorrow    1   \n",
       "26298  113.0       T  Go ahead and turn them in and then you can lea...    1   \n",
       "26299  114.0       T  If theres a specific type of problem you want ...    1   \n",
       "26300  114.0       T  If you would go ahead and turn off the microph...    1   \n",
       "\n",
       "      StudentTag                                    Transcript  \n",
       "0            nan    TalkBack.Year1.Saunders.Spring.021820.xlsx  \n",
       "1              1    TalkBack.Year1.Saunders.Spring.021820.xlsx  \n",
       "2            nan    TalkBack.Year1.Saunders.Spring.021820.xlsx  \n",
       "3            nan    TalkBack.Year1.Saunders.Spring.021820.xlsx  \n",
       "4            nan    TalkBack.Year1.Saunders.Spring.021820.xlsx  \n",
       "...          ...                                           ...  \n",
       "26296        nan  TalkBack.Year1.Saunders.Spring.020620-1.xlsx  \n",
       "26297        nan  TalkBack.Year1.Saunders.Spring.020620-1.xlsx  \n",
       "26298        nan  TalkBack.Year1.Saunders.Spring.020620-1.xlsx  \n",
       "26299        nan  TalkBack.Year1.Saunders.Spring.020620-1.xlsx  \n",
       "26300        nan  TalkBack.Year1.Saunders.Spring.020620-1.xlsx  \n",
       "\n",
       "[26301 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Turn':[i[0] for i in dataset], 'Speaker':[i[1] for i in dataset], 'Sentence':[i[2] for i in dataset], 'Tag':[i[3] for i in dataset],'StudentTag':[i[4] for i in dataset],'Transcript':[i[5] for i in dataset]})\n",
    "df = df.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../data/train_data_506.xlsx') #replace with test_data_63 for test data\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-processing \n",
    "\n",
    "- All lower cased\n",
    "- All punctuation removed\n",
    "- Converted all teachers to T tags\n",
    "- Converted all students to S tags\n",
    "- T labels range from  [0-6] - 0 stands for None\n",
    "- S are labelled None\n",
    "- Compiled all the data into single excel sheet\n",
    "- At present there are 91891 sentences in total\n",
    "\n",
    "Cleaning\n",
    "\n",
    "- [End of Class], [Class Ends] - Sentence in brackets\n",
    "- If Sentence contains a timestamp or date time stamp\n",
    "- If sentence is just . or ! or ? or empty\n",
    "- Speaker is a number (All of them are nans)\n",
    "- Speaker is nan\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Tuples from data - Student\n",
    "data = pd.read_excel('../data/train_data_506.xlsx') #replace with test_data_63 to generate test data\n",
    "empty_previous = ''\n",
    "sentence_tuple = []\n",
    "y = []\n",
    "flag  = 0\n",
    "# T->T 0->1 T->S S->S S->T\n",
    "for row in data.iterrows():\n",
    "    if row[1]['Speaker'] == 'T' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag=1\n",
    "        sentence_tuple.append([empty_previous,temp,row[1]['StudentTag']])\n",
    "        y.append(row[1]['StudentTag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 1:\n",
    "        sentence_tuple.append([temp,row[1]['Sentence'],row[1]['StudentTag']])\n",
    "        y.append(row[1]['StudentTag'])\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "        \n",
    "df = pd.DataFrame({'text_a':[i[0] for i in sentence_tuple], 'text_b':[i[1] for i in sentence_tuple], 'labels':[i[2] for i in sentence_tuple]})\n",
    "\n",
    "df.to_csv('../data/train_student.tsv',sep='\\t',index=False)   #replace with test_student to generate test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Tuples from data - teacher\n",
    "data = pd.read_excel('../data/test_data_506.xlsx') #replace with test_data_63 to generate test data\n",
    "empty_student = ''\n",
    "sentence_tuple = []\n",
    "y = []\n",
    "flag  = 0\n",
    "# T->T 0->1 T->S S->S S->T\n",
    "for row in data.iterrows():\n",
    "    if row[1]['Speaker'] == 'S' and flag == 2:\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 2\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        sentence_tuple.append([empty_student,temp,row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        sentence_tuple.append([empty_student,temp,row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 2:\n",
    "        sentence_tuple.append([temp,row[1]['Sentence'],row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        flag = 1\n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame({'text_a':[i[0] for i in sentence_tuple], 'text_b':[i[1] for i in sentence_tuple], 'labels':[i[2] for i in sentence_tuple]})\n",
    "\n",
    "df.to_csv('../data/train_teacher.tsv',sep='\\t',index=False)  #replace with test_teacher to generate test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
