{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This notebook is used to process the raw transcripts into a format that can then be used for model training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env/python\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import string\n",
    "import unicodedata\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Subset 1 and Subset 2\n",
    "path1 = '../data/Subset1_WithDialogActs/'\n",
    "subdirs = glob.glob('%s*'%(path1))\n",
    "\n",
    "path2 = '../data/Subset2_WithDialogActs/'\n",
    "subdirs.extend(glob.glob('%s*'%(path2)))                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503 63\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "To avoid overfitting the models we carefully divide the training and testing set. \n",
    "Testing set include some teachers who particiapted in Year 1. The transcripts from these teachers are not included\n",
    "in the training set. The teachers in this list were picked at random.\n",
    "'''\n",
    "\n",
    "train_subdirs =[]\n",
    "test_subdirs = []\n",
    "for item in subdirs:\n",
    "    if item.find(\"Travers.Spring\") != -1 or item.find(\"Barry.Spring\") != -1 \\\n",
    "    or item.find(\"Carroll\") != -1 or item.find(\"Saunders.Spring\") != -1 \\\n",
    "    or item.find(\"Keene\") != -1 or item.find(\"Carter\") != -1 or item.find(\"Basker\") != -1 :\n",
    "        test_subdirs.append(item)\n",
    "    else:\n",
    "        train_subdirs.append(item)\n",
    "print(len(train_subdirs), len(test_subdirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/strings/accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "temp = []\n",
    "flag = 0\n",
    "for dir in train_subdirs: #replace with test_subdirs to generate test data\n",
    "    if dir.endswith('.xlsx') and not dir.startswith('~'):\n",
    "        try:\n",
    "            temp_data = None\n",
    "            load_data = pd.read_excel(dir)\n",
    "            load_data['Sentence'] = load_data['Sentence'].str.replace(\"[\\(\\[].*?[\\)\\]]\", \"\", regex=True)\n",
    "            load_data = load_data[load_data['Sentence'] != \"\"]\n",
    "            mask = load_data['Sentence'].str.contains('(.*[\\(].*|.*[\\)].*|.*[\\[].*|.*[\\]].*)|(^[.?!]+$)|(^.*[0-9]{1,2}:[0-9]{1,2}:[0-9]{1,2}.*$)',regex=True,na=False)\n",
    "            temp_data = load_data[:][~mask]\n",
    "            temp_data = temp_data.loc[:, ~temp_data.columns.str.contains('^Unnamed')]\n",
    "            temp_data['Transcript'] = dir.split('/')[len(dir.split('/'))-1]\n",
    "            for item in temp_data.columns:\n",
    "                if item not in ['Teacher Tag', 'TimeStamp' ,'Turn','Student Tag','Sentence','Speaker','Transcript','DAMSLTag']:\n",
    "                    temp_data = temp_data.drop(columns=[item])\n",
    "            if flag == 0:\n",
    "                data = temp_data\n",
    "                flag = 1\n",
    "            else:\n",
    "                if len(data.columns) > 8:\n",
    "                    print(data.columns,dir)\n",
    "                data = data.append(temp_data, ignore_index=True,sort=False)\n",
    "        except Exception as e:\n",
    "            print(e,dir)\n",
    "            pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TimeStamp Turn Speaker                                           Sentence  \\\n",
      "0       NaN  NaN       T               Do you want to say it to the camera?   \n",
      "1       NaN  NaN    Jeff                        No I don’t want to say it.    \n",
      "2       NaN  NaN    Jeff  This is going to be the number in the square m...   \n",
      "3       NaN  NaN       T  Yeah, what have you written here, that’s very ...   \n",
      "4       NaN  NaN    Jeff               Zero times zero plus one equals one.   \n",
      "\n",
      "                     Teacher Tag                                 Student Tag  \\\n",
      "0  2 - keeping everyone together                                         NaN   \n",
      "1                            NaN                                    1 - none   \n",
      "2                            NaN                          4 - making a claim   \n",
      "3                       1 - none                                         NaN   \n",
      "4                            NaN  5 - providing evidence/providing reasoning   \n",
      "\n",
      "  DAMSLTag                                         Transcript  \n",
      "0       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
      "1       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
      "2       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
      "3       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
      "4       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...   {'sv', 'fc', 'b', 'ba', 'aa', 'qy', 'sd'}\n"
     ]
    }
   ],
   "source": [
    "data = data[(data['DAMSLTag'].notna()) & (data['DAMSLTag'] != '%')]\n",
    "print(data.head(), set(data['DAMSLTag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "bad_sentences = []\n",
    "bad_speakers = []\n",
    "num_sentences = []\n",
    "bad_entries = []\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "for entry in data.iterrows():\n",
    "    try:\n",
    "        if type(entry[1]['Speaker']) == int or entry[1]['Speaker'] == float:\n",
    "            bad_speakers.append(entry[1]['Speaker'])\n",
    "            continue\n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'datetime.time'>\" or repr(type(entry[1]['Sentence'])) == \"<type 'datetime.datetime'>\" or repr(entry[1]['Speaker']) == 'nan':\n",
    "            bad_sentences.append(entry[1]['Sentence'])\n",
    "            continue\n",
    "    \n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'int'>\" or repr(type(entry[1]['Sentence'])) == \"<type 'float'>\":\n",
    "            num_sentences.append(str(entry[1]['Sentence']))\n",
    "            entry[1]['Sentence'] = str(entry[1]['Sentence']).translate(translator)\n",
    "        if repr(type(entry[1]['Sentence'])) == \"<type 'str'>\":\n",
    "            entry[1]['Sentence'] = str(entry[1]['Sentence']).translate(translator)\n",
    "            \n",
    "        temp = unicodedata.normalize('NFKD', str(entry[1]['Sentence']).translate(translator))\n",
    "        \n",
    "        # Turn, Speaker, Sentence, Teacher Tag, Student Tag, Dialog Act tag\n",
    "        try:\n",
    "            tag = str(entry[1]['Teacher Tag']).split('-')[0].strip()\n",
    "        except Exception as e:\n",
    "            print(e,'####')\n",
    "        try:\n",
    "            stag = str(entry[1]['Student Tag']).split('-')[0].strip()\n",
    "        except Exception as e:\n",
    "            print(e,'####')\n",
    "        \n",
    "        sent = ' '.join([re.sub(r\"[^a-zA-Z0-9]+\", ' ', k) for k in temp.split(\" \")])\n",
    "        \n",
    "        if str(stag) != 'nan':\n",
    "            #print([entry[1]['Turn'],'S',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "            dataset.append([entry[1]['Turn'],'S',sent.strip(),tag,stag,entry[1]['DAMSLTag'],entry[1]['Transcript']])\n",
    "        elif str(tag) != 'nan':\n",
    "            #print([entry[1]['Turn'],'T',sent.strip(),tag,stag,entry[1]['Transcript']])\n",
    "            dataset.append([entry[1]['Turn'],'T',sent.strip(),tag,stag,entry[1]['DAMSLTag'],entry[1]['Transcript']])\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        bad_entries.append([entry[1]['Sentence'], entry[1]['Speaker']])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Turn</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "      <th>StudentTag</th>\n",
       "      <th>DAMSLTag</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>Do you want to say it to the camera</td>\n",
       "      <td>2</td>\n",
       "      <td>nan</td>\n",
       "      <td>sd</td>\n",
       "      <td>Video Mosaic Grade 6 2 variables 14.xlsx_with_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>No I don t want to say it</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "      <td>sd</td>\n",
       "      <td>Video Mosaic Grade 6 2 variables 14.xlsx_with_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>This is going to be the number in the square m...</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>sd</td>\n",
       "      <td>Video Mosaic Grade 6 2 variables 14.xlsx_with_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>Yeah what have you written here that s very in...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>sd</td>\n",
       "      <td>Video Mosaic Grade 6 2 variables 14.xlsx_with_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Zero times zero plus one equals one</td>\n",
       "      <td>nan</td>\n",
       "      <td>5</td>\n",
       "      <td>sd</td>\n",
       "      <td>Video Mosaic Grade 6 2 variables 14.xlsx_with_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191768</th>\n",
       "      <td>166</td>\n",
       "      <td>T</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>b</td>\n",
       "      <td>TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191769</th>\n",
       "      <td>167</td>\n",
       "      <td>T</td>\n",
       "      <td>zero or a yintercept</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>sd</td>\n",
       "      <td>TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191770</th>\n",
       "      <td>167</td>\n",
       "      <td>T</td>\n",
       "      <td>You said its undefined where it crosses the yaxis</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>sd</td>\n",
       "      <td>TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191771</th>\n",
       "      <td>167</td>\n",
       "      <td>T</td>\n",
       "      <td>Then that must be your vertical asymptote</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>sd</td>\n",
       "      <td>TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191772</th>\n",
       "      <td>168</td>\n",
       "      <td>T</td>\n",
       "      <td>Hey have a good book stacker stack the books t...</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>sd</td>\n",
       "      <td>TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191773 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Turn Speaker                                           Sentence  Tag  \\\n",
       "0       NaN       T                Do you want to say it to the camera    2   \n",
       "1       NaN       S                          No I don t want to say it  nan   \n",
       "2       NaN       S  This is going to be the number in the square m...  nan   \n",
       "3       NaN       T  Yeah what have you written here that s very in...    1   \n",
       "4       NaN       S                Zero times zero plus one equals one  nan   \n",
       "...     ...     ...                                                ...  ...   \n",
       "191768  166       T                                                Yes    1   \n",
       "191769  167       T                               zero or a yintercept    1   \n",
       "191770  167       T  You said its undefined where it crosses the yaxis    1   \n",
       "191771  167       T          Then that must be your vertical asymptote    1   \n",
       "191772  168       T  Hey have a good book stacker stack the books t...    1   \n",
       "\n",
       "       StudentTag DAMSLTag                                         Transcript  \n",
       "0             nan       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
       "1               1       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
       "2               4       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
       "3             nan       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
       "4               5       sd  Video Mosaic Grade 6 2 variables 14.xlsx_with_...  \n",
       "...           ...      ...                                                ...  \n",
       "191768        nan        b  TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...  \n",
       "191769        nan       sd  TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...  \n",
       "191770        nan       sd  TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...  \n",
       "191771        nan       sd  TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...  \n",
       "191772        nan       sd  TalkBack.Year1.Wolfram.Spring.011420-1.xlsx_wi...  \n",
       "\n",
       "[191773 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Turn':[i[0] for i in dataset], 'Speaker':[i[1] for i in dataset], \\\n",
    "                   'Sentence':[i[2] for i in dataset], 'Tag':[i[3] for i in dataset],\\\n",
    "                   'StudentTag':[i[4] for i in dataset], 'DAMSLTag':[i[5] for i in dataset],\n",
    "                   'Transcript':[i[6] for i in dataset]})\n",
    "df = df.applymap(lambda x: x.encode('unicode_escape').decode('utf-8') if isinstance(x, str) else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('../data/test_data_63_dailog_acts.xlsx') #replace with test_data_63 for test data\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-processing \n",
    "\n",
    "- All lower cased\n",
    "- All punctuation removed\n",
    "- Converted all teachers to T tags\n",
    "- Converted all students to S tags\n",
    "- T labels range from  [0-6] - 0 stands for None\n",
    "- S are labelled None\n",
    "- Compiled all the data into single excel sheet\n",
    "- At present there are 91891 sentences in total\n",
    "\n",
    "Cleaning\n",
    "\n",
    "- [End of Class], [Class Ends] - Sentence in brackets\n",
    "- If Sentence contains a timestamp or date time stamp\n",
    "- If sentence is just . or ! or ? or empty\n",
    "- Speaker is a number (All of them are nans)\n",
    "- Speaker is nan\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Tuples from data - Student\n",
    "data = pd.read_excel('../data/test_data_63_dailog_acts.xlsx') #replace with test_data_63 to generate test data\n",
    "empty_previous = ''\n",
    "sentence_tuple = []\n",
    "y = []\n",
    "flag  = 0\n",
    "# T->T 0->1 T->S S->S S->T\n",
    "for row in data.iterrows():\n",
    "    if row[1]['Speaker'] == 'T' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag=1\n",
    "        sentence_tuple.append([empty_previous,temp,row[1]['DAMSLTag'],row[1]['StudentTag']])\n",
    "        y.append(row[1]['StudentTag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 1:\n",
    "        sentence_tuple.append([temp,row[1]['Sentence'],row[1]['DAMSLTag'], row[1]['StudentTag']])\n",
    "        y.append(row[1]['StudentTag'])\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "        \n",
    "df = pd.DataFrame({'text_a':[i[0] for i in sentence_tuple], \\\n",
    "                   'text_b':[i[1] for i in sentence_tuple], \\\n",
    "                   'damsl_labels':[i[2] for i in sentence_tuple],\n",
    "                   'labels':[i[3] for i in sentence_tuple]})\n",
    "\n",
    "df.to_csv('../data/test_student_dact.tsv',sep='\\t',index=False)   #replace with test_student to generate test data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Tuples from data - teacher\n",
    "data = pd.read_excel('../data/test_data_63_dailog_acts.xlsx') #replace with test_data_63 to generate test data\n",
    "empty_student = ''\n",
    "sentence_tuple = []\n",
    "y = []\n",
    "flag  = 0\n",
    "# T->T 0->1 T->S S->S S->T\n",
    "for row in data.iterrows():\n",
    "    if row[1]['Speaker'] == 'S' and flag == 2:\n",
    "        temp =  row[1]['Sentence']\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'S' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 2\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 0:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        sentence_tuple.append([empty_student,temp,row[1]['DAMSLTag'],row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 1:\n",
    "        temp =  row[1]['Sentence']\n",
    "        flag = 1\n",
    "        sentence_tuple.append([empty_student,temp,row[1]['DAMSLTag'],row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        continue\n",
    "    if row[1]['Speaker'] == 'T' and flag == 2:\n",
    "        sentence_tuple.append([temp,row[1]['Sentence'],row[1]['DAMSLTag'],row[1]['Tag']])\n",
    "        y.append(row[1]['Tag'])\n",
    "        flag = 1\n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame({'text_a':[i[0] for i in sentence_tuple],\\\n",
    "                   'text_b':[i[1] for i in sentence_tuple],\\\n",
    "                   'damsl_labels':[i[2] for i in sentence_tuple],\\\n",
    "                   'labels':[i[3] for i in sentence_tuple]})\n",
    "\n",
    "df.to_csv('../data/test_teacher_dact.tsv',sep='\\t',index=False)  #replace with test_teacher to generate test data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
